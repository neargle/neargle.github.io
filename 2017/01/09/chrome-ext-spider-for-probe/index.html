<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  
  <title>Chrome Extensions Spider &amp; Downloader - Nearg1e</title>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script type="text/javascript" src="/js/highlight.pack.js"></script>
  <script type="text/javascript" src="http://tajs.qq.com/stats?sId=58637942" charset="UTF-8"></script>
  
    <link rel="icon" href="/favicon.ico">
  
  
    <link rel="alternative" href="/atom.xml" title="Nearg1e" type="application/atom+xml">
  
  <!--[if lt IE 9]>
    <script type="text/javascript" src="/js/html5.js"></script>
    <script type="text/javascript" src="/js/css3-mediaqueries.js"></script>
  <![endif]-->
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/css/highlight.css">

</head>
<body>
    <header id="header">
    <div class="nav-warp">
      <nav id="nav" class="w">
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
        <a id="nav-search" class="icon-search fr" onclick="show_search()" title="搜索"></a>
        <div id="nav-search-input" class="hide">
          <form class="search-form" onsubmit="return dispatch()">
            <input type="hidden" id="site" value="site:http://blog.neargle.com">
            <input type="text" id="q" class="input-text" name="q" placeholder="搜索">
            <input type="submit" value="" class="input-submit">
          </form>
        </div>
      </nav>
    </div>
    
  </header>

  <!-- <div id='wrap'> -->
    <div id='outer'>
      <section id="main"><article class="post">
  <header class="post-head">
    
  
    
      <h1 class="post-title">Chrome Extensions Spider &amp; Downloader</h1>
    
  

    
<time datetime="2017-01-09T05:42:21.000Z" class="post-time">2017-01-09</time>

  </header>
  
  <section class="post-content typo">
    <p>可以先看一下n0r00t的文章的这一篇:<a href="https://www.n0tr00t.com/2017/01/09/Chrome-Extensions-Probe.html，以及用chrome试用一下最后的成果POC:[http://server.n0tr00t.com/chrome/ext_probe.html](http://server.n0tr00t.com/chrome/ext_probe.html)，可以探测Chrome中已安装的扩展，配合Chrome扩展的一些漏洞，说不定能达到定点攻击的效果。" target="_blank" rel="external">https://www.n0tr00t.com/2017/01/09/Chrome-Extensions-Probe.html，以及用chrome试用一下最后的成果POC:[http://server.n0tr00t.com/chrome/ext_probe.html](http://server.n0tr00t.com/chrome/ext_probe.html)，可以探测Chrome中已安装的扩展，配合Chrome扩展的一些漏洞，说不定能达到定点攻击的效果。</a></p>
<p>蘑菇的同学一个很有趣的想法，在这个想法的基础上帮他写的爬虫项目，主要以实现目的为主，不过有几个点很有收获，稍微分享一下。主要的思路可以看上面的文章，简单来说就是：以script标签on事件的差异性，结合Chrome开发规范”version 2.0”的manifest.json中的<code>web_accessible_resources</code>，探测客户端所存在的扩展。</p>
<p>我这里主要负责的工作就是前期的数据准备啦。主要目的：获取爬虫获取Chrome扩展的一些信息包括：扩展ID，扩展名，Star数量，用户数量、类别、插件商店URL等信息，然后根据ID下载扩展的.crx文件进行解压，提取其manifest.json，解析manifest.json中的<code>web_accessible_resources</code>字段，生成一个json文件。</p>
<p>github地址：<a href="https://github.com/neargle/ChromeExtensionKnower" target="_blank" rel="external">https://github.com/neargle/ChromeExtensionKnower</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Usage: geknower.py [OPTIONS] COMMAND [ARGS]...&#10;&#10;Options:&#10;  --help  Show this message and exit.&#10;&#10;Commands:&#10;  EtxDownload        This commond will Download Chrome Etx .crx...&#10;  etxInfo            Crawl and update Chrome Etx infomation&#10;  spec-fileCheck     Check filename in web_accessible_resources is...&#10;  spec-weblistAgain  Re get weblist</span><br></pre></td></tr></table></figure>
<p>关于脚本如何使用，可以去看一下github上面的readme，这里主要先记录一下写程序时遇到的一些有趣的点，以备后人使用。看完这些可能更有助于你理解代码。</p>
<h2 id="Q-_Note">Q. Note</h2><h3 id="1-_Chrome_WebStore_Api">1. Chrome WebStore Api</h3><p>主要用到三个API: </p>
<ol>
<li>爬取chrome扩展信息：<code>https://chrome.google.com/webstore/ajax/item?hl=zh-CN&amp;gl=CN&amp;pv=20161108&amp;mce=atf,eed,pii,rtr,rlb,gtc,hcn,svp,wtd,c3d,ncr,ctm,ac,hot,euf,mac,fcf,rma,pot,evt,igb&amp;requestedCounts=infiniteWall:{limit}:0:false&amp;token=featured:0@10316222:7:false,mcol#top_picks_productivity:0@10316223:11:true,infiniteWall:0@10316253:{start}:false&amp;category={category}&amp;_reqid=3058318&amp;rt=j</code></li>
<li>根据ID下载<code>.crx</code>文件：<code>https://clients2.google.com/service/update2/crx?response=redirect&amp;prodversion=49.0&amp;x=id%3D{id}%26installsource%3Dondemand%26uc</code></li>
</ol>
<p>下载crx文件是比较简单的，主要是爬取chrome扩展信息的那个API，费了我和蘑菇一点神。主要看url中，我{}出来的start和limit的位置是比较奇特的，不像正常的翻页请求，根据start，limit和category可以获取到全部的chrome扩展信息。扩展的分类有：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">category_list = [</span><br><span class="line">    <span class="string">'ext/10-blogging'</span>,</span><br><span class="line">    <span class="string">'ext/12-shopping'</span>,</span><br><span class="line">    <span class="string">'ext/11-web-development'</span>,</span><br><span class="line">    <span class="string">'ext/1-communication'</span>,</span><br><span class="line">    <span class="string">'ext/7-productivity'</span>,</span><br><span class="line">    <span class="string">'ext/38-search-tools'</span>,</span><br><span class="line">    <span class="string">'ext/13-sports'</span>,</span><br><span class="line">    <span class="string">'ext/22-accessibility'</span>,</span><br><span class="line">    <span class="string">'ext/6-news'</span>,</span><br><span class="line">    <span class="string">'ext/14-fun'</span>,</span><br><span class="line">    <span class="string">'ext/28-photos'</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>其实还有一个’ext/15-by-google’分类，但是这个分类的扩展在其他分类中也存在，而且这个分类是不能用第一个Api爬去的，得使用<code>https://chrome.google.com/webstore/ajax/item?pv=20161108&amp;count=209&amp;category=ext/15-by-google</code>这个API。API中存在的pv可能是需要更新的。</p>
<h3 id="2-_拓展数据解析">2. 拓展数据解析</h3><p>一般这种ajax，返回的应该是正常的json格式，但是Chrome Webstore却不是，Chrome返回的的格式是这样的。</p>
<p><img src="./static/img/chrome-webstore-info-struct-json.png" alt=""></p>
<p>明显不是正常的json，经过测试之后，是可以根据这样<code>json.loads(res.lstrip(&quot;)]}&#39;\n&quot;))</code>解析成一个复杂的list的。然后再根据位置进行提取可以获得到我们所需的信息。其中要注意，users的信息是千分位字符串<code>1,000,000</code>，而且是有可能出现<code>1,000,000+</code>的情况，在处理数据的时候需要考虑进来。处理方法看<code>https://github.com/neargle/ChromeExtensionKnower/blob/master/lib/common.py#L8</code>。</p>
<h3 id="3-_解析”web_accessible_resources”">3. 解析”web_accessible_resources”</h3><p>我们需要<code>web_accessible_resources</code>中可以访问的资源，原本直接使用<code>web_accessible_resources</code>，但是发现<code>web_accessible_resources</code>中是可以使用’<em>‘做通配符的，所以我们需要获取crx中的所有文件路径对通配符进行匹配。但是与linux通配符又有一定区别。`/path/</em><code>是可以匹配到</code>path/zzz.png<code>的，所以如果要使用</code>fnmatch`进行处理的话，多进行一个对路径和通配符的操作。</p>
<p>实际编写脚本的过程中，因为这些问题得爬取数据下来观察数据才能发现不对，所以重复爬了好几次。浪费了很多时间。</p>
<p>还有一些小细节，比较繁琐就不描述了，有需要的可以看看项目代码。</p>
<h2 id="程序使用介绍">程序使用介绍</h2><p><a href="https://github.com/neargle/ChromeExtensionKnower/blob/master/README.md" target="_blank" rel="external">https://github.com/neargle/ChromeExtensionKnower/blob/master/README.md</a></p>
<h4 id="安装和运行">安装和运行</h4><p>pip3 install -r requirements.txt<br>python3 geknower.py</p>
<h4 id="帮助文档">帮助文档</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python3 geknower.py --help                                                                             master [a41c206] modified untracked&#10;[*] main start&#10;Usage: geknower.py [OPTIONS] COMMAND [ARGS]...&#10;&#10;Options:&#10;  --help  Show this message and exit.&#10;&#10;Commands:&#10;  etxDownload        This commond will Download Chrome Etx .crx...&#10;  etxInfo            Crawl and update Chrome Etx infomation&#10;  spec-fileCheck     Check filename in web_accessible_resources is...&#10;  spec-weblistAgain  Re get weblist&#10;&#10;&#10;$ python3 geknower.py etxDownload --help                                                                 master [a41c206] modified untracked&#10;[*] main start&#10;Usage: geknower.py etxDownload [OPTIONS]&#10;&#10;  This commond will Download Chrome Etx .crx file&#10;&#10;Options:&#10;  -O, --outfile TEXT    Output result a json file, default use&#10;                        config.py:conf[&#34;etx_info_weblist_file&#34;]&#10;  -f, --jsonfile TEXT   Input the jsonfile as baseinfo, default use&#10;                        config.py:conf[&#34;data_file&#34;]&#10;  -p, --tmppath TEXT    The program will download etx file to tmppath, default&#10;                        use config.py:conf[&#34;tmp_path&#34;]&#10;  -t, --thread INTEGER  Thread number, default use config.py:conf[&#34;threadnum&#34;]&#10;  -d, --deltmp          del the dowload config.py:conf[&#34;del_tmp&#34;]&#10;  --help                Show this message and exit.&#10;&#10;&#10;$ python3 geknower.py etxInfo --help                                                                     master [a41c206] modified untracked&#10;[*] main start&#10;Usage: geknower.py etxInfo [OPTIONS]&#10;&#10;  Crawl and update Chrome Etx infomation&#10;&#10;Options:&#10;  -O, --outfile TEXT   Output result a json file, default use&#10;                       config.py:conf[&#34;data_file&#34;]&#10;  -u, --users INTEGER  Only get the users great than the number, default 0 get&#10;                       all&#10;  --help               Show this message and exit.</span><br></pre></td></tr></table></figure>
<p>有几个配置的选项可以在命令行中指定，可以修改config.py修改成自己想要的配置。</p>
<h4 id="关于config">关于config</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">conf = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存插件信息的文件，文件格式是每一行一个json，存储一个插件信息</span></span><br><span class="line">conf[<span class="string">'data_file'</span>] = <span class="string">'./data/data2_1000_2_1.json'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成添加web_accessible_resources或者文件名列表所保存的json，这个生成会根据conf['data_file']内的插件信息进行生成</span></span><br><span class="line">conf[<span class="string">'etx_info_weblist_file'</span>] = <span class="string">'./data/test2.json'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户数限制，爬取数据时只爬取用户量多余该数的插件信息</span></span><br><span class="line">conf[<span class="string">'more_then_user_num'</span>] = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tmp目录，用于保存下载下来的.crx文件</span></span><br><span class="line">conf[<span class="string">'tmp_path'</span>] = <span class="string">'./tmp/'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载crx文件多线程时，指定线程数</span></span><br><span class="line">conf[<span class="string">'threadnum'</span>] = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否在解析之后删除下载的crx文件，如果以下载插件为目的可以不删除</span></span><br><span class="line">conf[<span class="string">'del_tmp'</span>] = <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否解析crx文件添加web_accessible_resources信息</span></span><br><span class="line">conf[<span class="string">'weblist'</span>] = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否解析crx文件添加crx解压之后生成的文件名列表</span></span><br><span class="line">conf[<span class="string">'filelist'</span>] = <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求的UA</span></span><br><span class="line">conf[<span class="string">'HTTP_HEADERS'</span>] = &#123;</span><br><span class="line">    <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) "</span></span><br><span class="line">                    <span class="string">"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2403.157 Safari/537.36"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所有的config配置都可以在响应的命令行选项里进行配置。</p>
<h4 id="关于已生成的数据文件">关于已生成的数据文件</h4><p>这里提供两个数据文件：</p>
<ol>
<li>扩展探测中用到数据文件：<a href="./data/etx_weblist_info_1k.txt">用户量1000+且带有解析后处理后的web_accessible_resources的插件信息</a></li>
<li>包含所有扩展信息的数据文件: <a href="./data/etx_info_all.txt">所有拓展信息</a></li>
</ol>
<h4 id="Example">Example</h4><p><code>python3 python3 geknower.py etxDownload -O out.txt -f data/etx_info_all.txt  -p /tmp/ -d -t 20</code><br><code>python3 geknower.py etxInfo -O out.txt -u 1000000</code></p>
<h2 id="最后">最后</h2><p>因为chrome插件开发者的质量层次不齐，不免还有很多未解决的问题。包括其最后的Poc的JavaScript中也留了一个很有趣的点，注意到人可以和我们联系。</p>

    <p class="origin-url">本文URL： <a href="http://blog.neargle.com/2017/01/09/chrome-ext-spider-for-probe/index.html">http://blog.neargle.com/2017/01/09/chrome-ext-spider-for-probe/index.html</a></p>
  </section>
  
  <footer class="post-foot">
    <section class="post-foot-warp clear">
      
  <ul class="post-tag icon-tag fl">
    
      <li><a href="/tags/安全研究/">#安全研究</a></li>
    
  </ul>

      
    </section>
  </footer>
  
</article>

    
<nav id="post-nav" class="clear">
  
  
    <a href="/2016/12/15/n0js-case1-writeup/" id="post-nav-older" class="post-nav-link-wrap fr" title="n0js case1 writeup">
      <div class="post-nav-title">n0js case1 writeup &raquo;</div>
    </a>
  
</nav>



<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
    </div>
  <!-- </div> -->
    <footer id="footer">
    <div class="foot-warp">
      <p>© 2014 Nearg1e</p>
    </div>
  </footer>
  <script src="/js/tools.js"></script>
  
  
  <script>
    var disqus_shortname = 'neargle';
    
    var disqus_url = 'http://blog.neargle.com/2017/01/09/chrome-ext-spider-for-probe/';
    
    (function(){
      var dsq = document.createElement('script');
      dsq.type = 'text/javascript';
      dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  
  
</body>
</html>
